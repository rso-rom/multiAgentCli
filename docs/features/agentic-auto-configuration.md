# ğŸ¤– Agentic Auto-Configuration - LLM mit Tool-Nutzung

## ğŸ¯ Ãœbersicht

**Das LLM ist jetzt ein Agent!** Statt dass wir im Code Web-Requests machen, kann das LLM **selbst Tools wie curl/wget nutzen**, um APIs zu erforschen.

### Was ist Agentic AI?

**Agentic AI** = AI, die **Tools nutzen** kann, um Aufgaben selbststÃ¤ndig zu lÃ¶sen.

**Vorher (Passive AI):**
```
Wir: "Recherchiere Gemini API"
LLM: "Basierend auf meinem Training..."
     [Nutzt veraltetes Wissen]
```

**Jetzt (Agentic AI):**
```
Wir: "Recherchiere Gemini API"
LLM: "Ich werde curl nutzen:"
     [TOOL:curl:https://docs.gemini.ai/api-reference]
     [System fÃ¼hrt curl aus]
LLM: "Basierend auf der aktuellen Dokumentation..."
     [Nutzt Live-Daten!]
```

---

## ğŸš€ Wie funktioniert es?

### 0. System-Capabilities erkennen (NEU! ğŸ‰)

Bevor das LLM Tools nutzen kann, erkennt das System verfÃ¼gbare Tools und fragt um Erlaubnis:

```
ğŸ” Detecting system capabilities...

ğŸ“‹ Detected System Capabilities:

Development Tools:
  âœ… vim (VIM - Vi IMproved 8.2)
  âœ… nano (GNU nano 5.4)

Package Managers:
  âœ… npm (9.6.7)

Version Control:
  âœ… git (git version 2.39.2)

? Allow AI agents to use these tools?
  âœ… Allow all detected tools
  âš™ï¸  Select specific tools
  âŒ No, use only safe defaults
```

**Warum wichtig?**
- ğŸ”’ **Sicherheit**: Du entscheidest, welche Tools das LLM nutzen darf
- ğŸ¯ **Transparenz**: Siehst genau, was auf deinem System verfÃ¼gbar ist
- ğŸ’¾ **Speichern**: Einmal erlaubt, wird nicht mehr gefragt (`.cacli-permissions.json`)

Mehr Details: [Capability Detection System](./capability-detection.md)

### 1. LLM bekommt erlaubte Tools

Das LLM wird informiert, welche Tools verfÃ¼gbar sind:

```typescript
Tools available (with user permission):
- curl: Fetch web content
- wget: Download files
- http_get: Simple HTTP requests
- git: Clone repositories
- npm: Query npm registry

Format: [TOOL:curl:https://example.com]
```

### 2. LLM entscheidet selbst

```
LLM: "To research the Gemini API, I will first fetch the docs:
      [TOOL:curl:https://docs.gemini.ai/api-reference]

      Then check the API endpoint:
      [TOOL:http_get:https://generativelanguage.googleapis.com/v1beta/models]"
```

### 3. System fÃ¼hrt Tools aus

```typescript
ğŸ”§ Executing tool: curl https://docs.gemini.ai/api-reference
âœ… Tool executed successfully (15432 bytes)

ğŸ”§ Executing tool: http_get https://generativelanguage.googleapis.com/v1beta/models
âœ… Tool executed successfully (2891 bytes)
```

### 4. LLM analysiert Ergebnisse

```
LLM: "Based on the documentation and API response:

      API_URL: https://generativelanguage.googleapis.com/v1beta
      AUTH_TYPE: api-key
      DEFAULT_MODEL: gemini-pro
      SUPPORTS_VISION: YES
      SUPPORTS_STREAMING: YES"
```

---

## ğŸ’¡ 3 Modi verfÃ¼gbar

### Modus 1: **Agentic Tool Use** (Standard, Beste QualitÃ¤t)

```bash
cacli configure backend gemini --api-key KEY
```

**Was passiert:**
```
ğŸ¤– Agentic Tool Use: Enabled (LLM can use curl/wget)
ğŸ”„ Agentic iteration 1/3...
ğŸ”§ Executing 2 tool call(s)...
  âœ… curl:https://docs.gemini.ai/api-reference
  âœ… http_get:https://generativelanguage.googleapis.com/v1beta/models
ğŸ”„ Agentic iteration 2/3...
âœ… Research complete!
```

**Vorteile:**
- âœ… LLM entscheidet selbst, welche URLs wichtig sind
- âœ… Kann mehrere Iterationen machen
- âœ… Passt sich dynamisch an
- âœ… Beste Ergebnisse

### Modus 2: **Web Search** (Pre-Fetch)

```bash
cacli configure backend gemini --api-key KEY --no-agentic-tools
```

**Was passiert:**
```
ğŸŒ Web Search: Enabled (pre-fetch documentation)
ğŸŒ Searching web for gemini API documentation...
âœ… Found documentation at: https://docs.gemini.ai/api-reference
ğŸ” Searching GitHub for gemini examples...
âœ… Found 847 GitHub examples
```

**Vorteile:**
- âœ… Schneller (keine Iterationen)
- âœ… Weniger LLM-Calls
- âš ï¸  Weniger flexibel

### Modus 3: **LLM Knowledge Only** (Offline)

```bash
cacli configure backend gemini --api-key KEY --no-web-search
```

**Was passiert:**
```
ğŸ“š LLM Knowledge Only: No web access
[Nutzt nur Training-Daten]
```

**Vorteile:**
- âœ… Funktioniert offline
- âœ… Am schnellsten
- âš ï¸  Kann veraltet sein

---

## ğŸ“Š Modi-Vergleich

| Feature | Agentic ğŸ¤– | Web Search ğŸŒ | LLM Only ğŸ“š |
|---------|-----------|---------------|-------------|
| **Genauigkeit** | â­â­â­â­â­ | â­â­â­â­ | â­â­â­ |
| **AktualitÃ¤t** | Live-Daten | Live-Daten | Training-Cutoff |
| **FlexibilitÃ¤t** | LLM entscheidet | Vordefiniert | Keine |
| **Iterationen** | Ja (max 3) | Nein | Nein |
| **Geschwindigkeit** | â­â­ (~10-20s) | â­â­â­ (~5-10s) | â­â­â­â­â­ (~2s) |
| **LLM-Calls** | 1-3 | 1 | 1 |
| **Internet** | Erforderlich | Erforderlich | Nicht nÃ¶tig |

**Empfehlung:** Agentic Tool Use fÃ¼r beste Ergebnisse!

---

## ğŸ” Technische Details

### Tool-Format

Das LLM nutzt folgendes Format fÃ¼r Tool-Calls:

```
[TOOL:tool_name:arguments]
```

**Beispiele:**

```
[TOOL:curl:https://docs.gemini.ai/api-reference]
[TOOL:wget:https://api.example.com/docs.html]
[TOOL:http_get:https://api.example.com/v1/models]
```

### Agentic Loop

```typescript
while (iteration < maxIterations) {
  // 1. LLM gibt Antwort (mit Tool-Calls)
  const response = await llm.chat(prompt);

  // 2. Parse Tool-Calls
  const toolCalls = parseToolCalls(response);

  // 3. FÃ¼hre Tools aus
  const results = await executeTools(toolCalls);

  // 4. Gib Feedback an LLM
  prompt = `Tool results: ${results}\n\nAnalyze and continue...`;

  // 5. Repeat oder finish
}
```

### Sicherheit

**Sanitization:**
```typescript
// Entfernt gefÃ¤hrliche Zeichen:
- ; | & ` $ ( )  // Shell-Operators
- --exec, --config  // GefÃ¤hrliche Flags

// Erlaubt nur sichere curl/wget Optionen
```

**Timeout:**
```typescript
timeout: 10000ms  // 10 Sekunden max
maxBuffer: 10000  // Max 10KB Output
```

**Output-Limiting:**
```typescript
// Output wird auf 10KB begrenzt
if (output.length > 10000) {
  output = output.substring(0, 10000) + '\n[truncated]';
}
```

---

## ğŸ¯ Use Cases

### Use Case 1: Unbekanntes Backend

**Szenario:** Du willst ein neues, unbekanntes Backend nutzen.

```bash
cacli configure backend fireworks --api-key KEY
```

**Agentic LLM:**
```
ğŸ¤– "I don't have training data for 'fireworks', let me research:

[TOOL:curl:https://docs.fireworks.ai/api-reference]
[TOOL:http_get:https://api.fireworks.ai/v1/models]

After analyzing the docs, I found:
API_URL: https://api.fireworks.ai/v1
..."
```

**Ergebnis:** Auch unbekannte Backends funktionieren! âœ…

### Use Case 2: API-Version-Update

**Szenario:** Backend hat API aktualisiert.

**Mit Agentic:**
```bash
cacli configure backend gemini  # Holt neueste Version!
```

Das LLM fetcht immer die **aktuelle** Dokumentation.

### Use Case 3: Custom Endpoints

**Szenario:** Backend nutzt non-standard URLs.

**Agentic LLM probiert mehrere:**
```
[TOOL:curl:https://docs.backend.ai/api-reference]  # âŒ 404
[TOOL:curl:https://backend.ai/docs/api]  # âŒ 404
[TOOL:curl:https://developers.backend.com/api]  # âœ… 200
```

Findet automatisch die richtige URL!

---

## ğŸ› ï¸ VerfÃ¼gbare Tools

### Web Tools

**1. curl** - HTTP Requests
```bash
[TOOL:curl:https://api.example.com/docs]
```
- API-Dokumentation abrufen
- Endpoints testen
- HTML/JSON-Responses

**2. wget** - File Download
```bash
[TOOL:wget:https://example.com/docs.html]
```
- Dokumentations-Downloads
- Static Files
- GroÃŸe Responses

**3. http_get** - Simple GET
```bash
[TOOL:http_get:https://api.example.com/v1/info]
```
- Einfache GET-Requests
- API-Tests

### Git Tools

**4. git_clone** - Clone Repository
```bash
[TOOL:git_clone:https://github.com/user/repo.git]
```
- SDK Repositories klonen
- Code-Beispiele abrufen
- Nur HTTPS URLs (Sicherheit)

### Package Tools

**5. npm_info** - Package Info
```bash
[TOOL:npm_info:@google/generative-sdk]
```
- NPM Package-Informationen
- Version & Dependencies
- Repository-Links

### File Tools

**6. cat** - Read Files
```bash
[TOOL:cat:package.json]
[TOOL:cat:src/index.ts]
```
- Dateien lesen
- Code analysieren
- Config-Files prÃ¼fen

**7. grep** - Search in Files
```bash
[TOOL:grep:API_KEY .env]
[TOOL:grep:export src/index.ts]
```
- In Dateien suchen
- Patterns finden

### Code Execution

**8. node** - Run JavaScript
```bash
[TOOL:node:-e "console.log(JSON.parse('{}'))"]
```
- JavaScript ausfÃ¼hren
- JSON parsen
- Quick Tests

### JSON Tools

**9. jq** - Parse JSON
```bash
[TOOL:jq:. package.json]
```
- JSON formatieren
- Felder extrahieren

### Shell Tools

**10. shell** - Safe Commands
```bash
[TOOL:shell:ls -la]
[TOOL:shell:pwd]
[TOOL:shell:which node]
```
- Whitelist: ls, pwd, date, uname, which, etc.
- Sichere System-Befehle

---

## ğŸ“ Beispiel-Ablauf

### Basic Workflow (Web Tools Only)

```bash
$ cacli configure backend mistral --api-key YOUR_KEY

ğŸ”„ Agentic iteration 1/3...
ğŸ”§ Executing 2 tool call(s)...
  ğŸ”§ Executing tool: curl https://docs.mistral.ai/api-reference
  âœ… Tool executed successfully (8523 bytes)
  ğŸ”§ Executing tool: http_get https://api.mistral.ai/v1/models
  âœ… Tool executed successfully (1842 bytes)

âœ… Research complete!
```

### Advanced Workflow (All Tools)

```bash
$ cacli configure backend gemini --api-key YOUR_KEY

ğŸ”„ Agentic iteration 1/3...
LLM: "I'll research the Gemini API comprehensively:"

ğŸ”§ Executing 5 tool call(s)...

  # Web Research
  ğŸ”§ curl https://docs.gemini.ai/api-reference
  âœ… Tool executed successfully (12453 bytes)

  # Check for SDK
  ğŸ”§ npm_info @google-ai/generativelanguage
  âœ… Tool executed successfully (3421 bytes)
  â†’ Found SDK! Repository: https://github.com/google/generative-ai-js

  # Clone SDK for examples
  ğŸ”§ git_clone https://github.com/google/generative-ai-js.git
  âœ… Tool executed successfully
  â†’ Cloned to: generative-ai-js/

  # Read package structure
  ğŸ”§ cat generative-ai-js/package.json
  âœ… Tool executed successfully
  â†’ Found entry point: dist/index.js

  # Search for API endpoint in code
  ğŸ”§ grep "https://generativelanguage" generative-ai-js/src/*.ts
  âœ… Tool executed successfully
  â†’ Found: API_URL = https://generativelanguage.googleapis.com/v1beta

ğŸ”„ Agentic iteration 2/3...
LLM: "Based on the SDK code, I'll extract more details:"

ğŸ”§ Executing 2 tool call(s)...

  # Parse package.json to get version
  ğŸ”§ node -e "const pkg = require('./generative-ai-js/package.json'); console.log(pkg.version)"
  âœ… Tool executed successfully
  â†’ Version: 0.1.3

  # Check what models are available
  ğŸ”§ http_get https://generativelanguage.googleapis.com/v1beta/models
  âœ… Tool executed successfully (2891 bytes)
  â†’ Models: gemini-pro, gemini-pro-vision

âœ… Research complete!
   API URL: https://generativelanguage.googleapis.com/v1beta
   Auth: api-key
   Default Model: gemini-pro
   Streaming: Yes
   Vision: Yes (gemini-pro-vision)

ğŸ”¨ Generating backend code...
   [Using SDK structure as template]

âœ… Saved: src/backends/gemini.ts

ğŸ‰ Auto-configuration complete!
```

### LLM Tool Chain Example

**Was das LLM macht:**

```
Iteration 1: Broad Research
â”œâ”€ [TOOL:curl:https://docs.gemini.ai/api-reference]
â”œâ”€ [TOOL:npm_info:@google-ai/generativelanguage]
â””â”€ Decision: "SDK exists! Let me clone it for better understanding"

Iteration 2: Deep Dive
â”œâ”€ [TOOL:git_clone:https://github.com/google/generative-ai-js.git]
â”œâ”€ [TOOL:cat:generative-ai-js/package.json]
â”œâ”€ [TOOL:grep:API_URL generative-ai-js/src/*.ts]
â””â”€ Decision: "Found all info! Let me verify endpoints"

Iteration 3: Verification
â”œâ”€ [TOOL:http_get:https://api.../models]
â”œâ”€ [TOOL:node:-e "console.log(JSON.parse(response))"]
â””â”€ Decision: "Complete! I have all necessary information"
```

---

## ğŸ”§ Erweiterte Nutzung

### Custom Tool Timeout

```typescript
const toolExecutor = new ToolExecutor();
toolExecutor.timeout = 20000;  // 20 Sekunden
```

### Mehr Iterationen erlauben

```typescript
// In auto-configurator.ts:
const maxIterations = 5;  // Standard: 3
```

### Debug-Modus

```bash
DEBUG=1 cacli configure backend gemini

# Zeigt alle Tool-Calls und Responses
```

---

## ğŸ¨ LLM-Verhalten

### Was das LLM typischerweise macht:

**Iteration 1:**
```
"I'll start by fetching the main documentation:"
[TOOL:curl:https://docs.gemini.ai/api-reference]
```

**Iteration 2:**
```
"Based on the docs, let me check available models:"
[TOOL:http_get:https://generativelanguage.googleapis.com/v1beta/models]
```

**Iteration 3:**
```
"Now I have all information needed:
API_URL: ...
AUTH_TYPE: ...
..."
```

### Fallback-Logik:

1. **Iteration 1 failed?** â†’ Versucht alternative URLs
2. **Iteration 2 failed?** â†’ Nutzt verfÃ¼gbare Infos
3. **Iteration 3 failed?** â†’ Fallback auf Web-Search-Modus

---

## âš™ï¸ Konfiguration

### Agentic deaktivieren

```bash
# Nutze Web-Search statt Agentic:
cacli configure backend gemini --no-agentic-tools

# Nutze nur LLM-Wissen:
cacli configure backend gemini --no-web-search
```

### Programmatisch

```typescript
import { AutoConfigurator } from './setup/auto-configurator';

// Agentic aktiviert:
const configurator = new AutoConfigurator(
  llm,          // LLM Backend
  true,         // Web Search
  true          // Agentic Tools
);

// Nur Web Search:
const configurator = new AutoConfigurator(llm, true, false);

// Nur LLM:
const configurator = new AutoConfigurator(llm, false, false);
```

---

## ğŸ§ª Testing

### Test 1: Agentic Mode

```bash
cacli configure backend gemini --api-key KEY

# Erwartung:
# - LLM macht Tool-Calls
# - curl/wget werden ausgefÃ¼hrt
# - 1-3 Iterationen
# - Erfolgreiche Konfiguration
```

### Test 2: Tool-Call Parsing

```typescript
const response = `
I'll fetch the docs:
[TOOL:curl:https://docs.example.com]

Then check the API:
[TOOL:http_get:https://api.example.com/v1]
`;

const calls = toolExecutor.parseToolCalls(response);
// Ergebnis: 2 Tool-Calls erkannt
```

### Test 3: Fallback

```bash
# Ollama offline â†’ Fallback auf LLM-Wissen
pkill ollama
cacli configure backend mistral

# Sollte trotzdem funktionieren (mit veralteten Daten)
```

---

## ğŸ“ Fazit

### Das System ist jetzt:

1. **ğŸ¤– Agentic** - LLM nutzt Tools selbststÃ¤ndig
2. **ğŸŒ Connected** - Holt Live-Daten aus dem Internet
3. **ğŸ”„ Iterative** - Kann mehrfach nachfragen
4. **ğŸ¯ Smart** - Passt sich an verschiedene APIs an
5. **ğŸ›¡ï¸ Sicher** - Sanitization & Timeouts

### Workflow:

```
Nutzer: "Configure Gemini"
    â†“
LLM: "Ich nutze curl..."
    â†“
System: [FÃ¼hrt curl aus]
    â†“
LLM: "Basierend auf der Doku..."
    â†“
System: [Generiert Code]
    â†“
âœ… Fertig!
```

### NÃ¤chste Schritte:

1. **Ausprobieren:**
   ```bash
   cacli configure backend gemini --api-key YOUR_KEY
   ```

2. **Vergleichen:**
   ```bash
   # Agentic vs. Web Search vs. LLM Only
   ```

3. **Erweitern:**
   - Weitere Tools hinzufÃ¼gen (git, npm, etc.)
   - Mehr Iterationen erlauben
   - Custom Tool-Executor schreiben

ğŸš€ **Das System kann sich jetzt selbst erweitern - mit Live-Internet-Zugriff!**
